{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21a4384",
   "metadata": {},
   "source": [
    "# ------------------------------------\n",
    "# No Alpha\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3da13e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 6 -> R²: 0.9127, MSE: 0.2506\n",
      "Seed 40 -> R²: 0.9168, MSE: 0.2424\n",
      "Seed 43 -> R²: 0.9247, MSE: 0.2668\n",
      "Seed 118 -> R²: 0.9190, MSE: 0.2197\n",
      "Seed 146 -> R²: 0.9253, MSE: 0.2082\n",
      "\n",
      "--- Final Summary (Mean ± Std) ---\n",
      "R² Score: 0.9197 ± 0.0048\n",
      "MSE     : 0.2376 ± 0.0211\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "GRAPH_SEED = 11\n",
    "\n",
    "GRAPH_LEARN_MEAN = 0.5\n",
    "GRAPH_LEARN_STD = 0.01\n",
    "GRAPH_LEARN_EPOCHS = 5000\n",
    "GRAPH_LEARN_BETA = 0.01\n",
    "GRAPH_LEARN_ETA = 0.001\n",
    "\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "\n",
    "# ------------------------------------\n",
    "# Learn Graph Structure (L2 regularizer only)\n",
    "# ------------------------------------\n",
    "def learn_graph(X: torch.Tensor, seed_graph: int) -> np.ndarray:\n",
    "    X_np = X.cpu().numpy()\n",
    "    N = X_np.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(seed_graph)\n",
    "    W = rng.normal(GRAPH_LEARN_MEAN, GRAPH_LEARN_STD, size=(N, N))\n",
    "\n",
    "    i_idx, j_idx = np.triu_indices(N, k=1)\n",
    "    w = W[i_idx, j_idx].copy()\n",
    "    delL = np.sum((X_np[i_idx] - X_np[j_idx]) ** 2, axis=1)\n",
    "\n",
    "    best_w = w.copy()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for _ in range(GRAPH_LEARN_EPOCHS):\n",
    "        grad = 2.0 * delL + GRAPH_LEARN_BETA * w\n",
    "        w -= GRAPH_LEARN_ETA * grad\n",
    "        np.clip(w, 0.0, None, out=w)\n",
    "\n",
    "        loss = (delL * w).sum() + (GRAPH_LEARN_BETA / 2.0) * (w ** 2).sum()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_w = w.copy()\n",
    "\n",
    "    adj = np.zeros((N, N), dtype=int)\n",
    "    adj[i_idx[best_w > 0], j_idx[best_w > 0]] = 1\n",
    "    adj[j_idx[best_w > 0], i_idx[best_w > 0]] = 1\n",
    "\n",
    "    return adj\n",
    "\n",
    "# ------------------------------------\n",
    "# GNN Model\n",
    "# ------------------------------------\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# ------------------------------------\n",
    "# Train and Evaluate for One Seed\n",
    "# ------------------------------------\n",
    "def run_single_seed(X_raw, Y_raw, seed_model, seed_graph):\n",
    "    np.random.seed(seed_model)\n",
    "    torch.manual_seed(seed_model)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed_model)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_np = scaler.fit_transform(np.abs(X_raw.cpu().numpy()))\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "\n",
    "    adj = learn_graph(X, seed_graph)\n",
    "    edge_index = torch.tensor(np.vstack(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed_model)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed_model)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(X.shape[0], dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index.to(DEVICE)\n",
    "    )\n",
    "    masks = {k: get_mask(v).to(DEVICE) for k, v in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx])}\n",
    "\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=200)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_true = data.y\n",
    "\n",
    "    r2 = r2_score(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "    mse = mean_squared_error(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "\n",
    "    return r2, mse\n",
    "\n",
    "# ------------------------------------\n",
    "# Main Execution\n",
    "# ------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"1000_cylindrical_anomalies.csv\")\n",
    "    X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "    Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "\n",
    "    SEEDS = [6,40,43,118,146]  \n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        r2, mse = run_single_seed(X_raw, Y_raw, seed_model=seed, seed_graph=GRAPH_SEED)\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "        print(f\"Seed {seed} -> R²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    mse_scores = np.array(mse_scores)\n",
    "\n",
    "    print(\"\\n--- Final Summary (Mean ± Std) ---\")\n",
    "    print(f\"R² Score: {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "    print(f\"MSE     : {mse_scores.mean():.4f} ± {mse_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7bf61f",
   "metadata": {},
   "source": [
    "# ------------------------------------\n",
    "# No Beta\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f781f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 10 -> R²: 0.9232, MSE: 0.2845\n",
      "Seed 22 -> R²: 0.9225, MSE: 0.3082\n",
      "Seed 48 -> R²: 0.9121, MSE: 0.3820\n",
      "Seed 60 -> R²: 0.9298, MSE: 0.2537\n",
      "Seed 74 -> R²: 0.9109, MSE: 0.3766\n",
      "\n",
      "--- Final Summary (Mean ± Std) ---\n",
      "R² Score: 0.9197 ± 0.0072\n",
      "MSE     : 0.3210 ± 0.0507\n",
      "\n",
      "Top 10 Learned Edges for Seed 10:\n",
      "Edge (574, 812) -> Weight: 2.9143\n",
      "Edge (511, 990) -> Weight: 2.8546\n",
      "Edge (575, 698) -> Weight: 2.3089\n",
      "Edge (381, 819) -> Weight: 2.2682\n",
      "Edge (248, 779) -> Weight: 2.2496\n",
      "Edge (73, 186) -> Weight: 2.2031\n",
      "Edge (350, 597) -> Weight: 2.1839\n",
      "Edge (283, 325) -> Weight: 2.1314\n",
      "Edge (498, 818) -> Weight: 2.1241\n",
      "Edge (861, 956) -> Weight: 2.0665\n",
      "\n",
      "Top 10 Learned Edges for Seed 22:\n",
      "Edge (574, 812) -> Weight: 2.9143\n",
      "Edge (511, 990) -> Weight: 2.8546\n",
      "Edge (575, 698) -> Weight: 2.3089\n",
      "Edge (381, 819) -> Weight: 2.2682\n",
      "Edge (248, 779) -> Weight: 2.2496\n",
      "Edge (73, 186) -> Weight: 2.2031\n",
      "Edge (350, 597) -> Weight: 2.1839\n",
      "Edge (283, 325) -> Weight: 2.1314\n",
      "Edge (498, 818) -> Weight: 2.1241\n",
      "Edge (861, 956) -> Weight: 2.0665\n",
      "\n",
      "Top 10 Learned Edges for Seed 48:\n",
      "Edge (574, 812) -> Weight: 2.9143\n",
      "Edge (511, 990) -> Weight: 2.8546\n",
      "Edge (575, 698) -> Weight: 2.3089\n",
      "Edge (381, 819) -> Weight: 2.2682\n",
      "Edge (248, 779) -> Weight: 2.2496\n",
      "Edge (73, 186) -> Weight: 2.2031\n",
      "Edge (350, 597) -> Weight: 2.1839\n",
      "Edge (283, 325) -> Weight: 2.1314\n",
      "Edge (498, 818) -> Weight: 2.1241\n",
      "Edge (861, 956) -> Weight: 2.0665\n",
      "\n",
      "Top 10 Learned Edges for Seed 60:\n",
      "Edge (574, 812) -> Weight: 2.9143\n",
      "Edge (511, 990) -> Weight: 2.8546\n",
      "Edge (575, 698) -> Weight: 2.3089\n",
      "Edge (381, 819) -> Weight: 2.2682\n",
      "Edge (248, 779) -> Weight: 2.2496\n",
      "Edge (73, 186) -> Weight: 2.2031\n",
      "Edge (350, 597) -> Weight: 2.1839\n",
      "Edge (283, 325) -> Weight: 2.1314\n",
      "Edge (498, 818) -> Weight: 2.1241\n",
      "Edge (861, 956) -> Weight: 2.0665\n",
      "\n",
      "Top 10 Learned Edges for Seed 74:\n",
      "Edge (574, 812) -> Weight: 2.9143\n",
      "Edge (511, 990) -> Weight: 2.8546\n",
      "Edge (575, 698) -> Weight: 2.3089\n",
      "Edge (381, 819) -> Weight: 2.2682\n",
      "Edge (248, 779) -> Weight: 2.2496\n",
      "Edge (73, 186) -> Weight: 2.2031\n",
      "Edge (350, 597) -> Weight: 2.1839\n",
      "Edge (283, 325) -> Weight: 2.1314\n",
      "Edge (498, 818) -> Weight: 2.1241\n",
      "Edge (861, 956) -> Weight: 2.0665\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# ------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEEDS = [10,22,48,60,74]\n",
    "GRAPH_SEED = 11\n",
    "\n",
    "GRAPH_LEARN_MEAN = 0.5\n",
    "GRAPH_LEARN_STD = 0.01\n",
    "GRAPH_LEARN_EPOCHS = 5000\n",
    "GRAPH_LEARN_ALPHA = 1.0\n",
    "GRAPH_LEARN_ETA = 0.001\n",
    "\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "\n",
    "# ------------------------------------\n",
    "# Learn Graph Structure (All edges with positive weight)\n",
    "# ------------------------------------\n",
    "def learn_graph(X: torch.Tensor, seed_graph: int):\n",
    "    X_np = X.cpu().numpy()\n",
    "    N = X_np.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(seed_graph)\n",
    "    W = rng.normal(GRAPH_LEARN_MEAN, GRAPH_LEARN_STD, size=(N, N))\n",
    "\n",
    "    i_idx, j_idx = np.triu_indices(N, k=1)\n",
    "    w = W[i_idx, j_idx].copy()\n",
    "    delL = np.sum((X_np[i_idx] - X_np[j_idx]) ** 2, axis=1)\n",
    "\n",
    "    row = np.concatenate([i_idx, j_idx])\n",
    "    col = np.concatenate([np.arange(len(i_idx)), np.arange(len(j_idx))])\n",
    "    S = coo_matrix((np.ones(len(row)), (row, col)), shape=(N, len(i_idx))).tocsc()\n",
    "    S_T = S.T\n",
    "\n",
    "    best_w = w.copy()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for _ in range(GRAPH_LEARN_EPOCHS):\n",
    "        Sw = S.dot(w)\n",
    "        inv_Sw = np.zeros_like(Sw)\n",
    "        nonzero = Sw > 0\n",
    "        inv_Sw[nonzero] = 1.0 / Sw[nonzero]\n",
    "        grad = 2.0 * delL - GRAPH_LEARN_ALPHA * S_T.dot(inv_Sw)\n",
    "        w -= GRAPH_LEARN_ETA * grad\n",
    "        np.clip(w, 0.0, None, out=w)\n",
    "\n",
    "        loss = (delL * w).sum() - GRAPH_LEARN_ALPHA * np.sum(np.log(Sw[nonzero]))\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_w = w.copy()\n",
    "\n",
    "    # Use all edges with positive weight\n",
    "    valid_mask = best_w > 0\n",
    "    adj = np.zeros((N, N), dtype=int)\n",
    "    adj[i_idx[valid_mask], j_idx[valid_mask]] = 1\n",
    "    adj[j_idx[valid_mask], i_idx[valid_mask]] = 1\n",
    "\n",
    "    return adj, best_w, i_idx, j_idx\n",
    "\n",
    "# ------------------------------------\n",
    "# GNN Model\n",
    "# ------------------------------------\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# ------------------------------------\n",
    "# Train and Evaluate for One Seed\n",
    "# ------------------------------------\n",
    "def run_single_seed(X_raw, Y_raw, seed_model, seed_graph):\n",
    "    np.random.seed(seed_model)\n",
    "    torch.manual_seed(seed_model)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed_model)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_np = scaler.fit_transform(np.abs(X_raw.cpu().numpy()))\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "\n",
    "    adj, weights, i_idx, j_idx = learn_graph(X, seed_graph)\n",
    "    edge_index = torch.tensor(np.vstack(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed_model)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed_model)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(X.shape[0], dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index.to(DEVICE)\n",
    "    )\n",
    "    masks = {k: get_mask(v).to(DEVICE) for k, v in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx])}\n",
    "\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=20)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_true = data.y\n",
    "\n",
    "    r2 = r2_score(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "    mse = mean_squared_error(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "\n",
    "    return r2, mse, weights, i_idx, j_idx\n",
    "\n",
    "# ------------------------------------\n",
    "# Main Execution\n",
    "# ------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"1000_cylindrical_anomalies.csv\")\n",
    "    X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "    Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "\n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "    all_weights = []\n",
    "    all_edges = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        r2, mse, weights, i_idx, j_idx = run_single_seed(X_raw, Y_raw, seed_model=seed, seed_graph=GRAPH_SEED)\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "        all_weights.append(weights)\n",
    "        all_edges.append((i_idx, j_idx))\n",
    "        print(f\"Seed {seed} -> R²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    mse_scores = np.array(mse_scores)\n",
    "\n",
    "    print(\"\\n--- Final Summary (Mean ± Std) ---\")\n",
    "    print(f\"R² Score: {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "    print(f\"MSE     : {mse_scores.mean():.4f} ± {mse_scores.std():.4f}\")\n",
    "\n",
    "    # Print top 10 weighted edges for each seed\n",
    "    for seed, weights, (i_idx, j_idx) in zip(SEEDS, all_weights, all_edges):\n",
    "        edge_list = list(zip(i_idx, j_idx))\n",
    "        top_indices = np.argsort(weights)[-10:]\n",
    "        print(f\"\\nTop 10 Learned Edges for Seed {seed}:\")\n",
    "        for idx in reversed(top_indices):\n",
    "            print(f\"Edge {edge_list[idx]} -> Weight: {weights[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d1abf",
   "metadata": {},
   "source": [
    "# ------------------------------------\n",
    "# NO Alpha and No Beta\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "149f2d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 11 -> R²: 0.9056, MSE: 0.3651\n",
      "Seed 18 -> R²: 0.9060, MSE: 0.3309\n",
      "Seed 36 -> R²: 0.9054, MSE: 0.3054\n",
      "Seed 40 -> R²: 0.9035, MSE: 0.2809\n",
      "Seed 67 -> R²: 0.9058, MSE: 0.3067\n",
      "\n",
      "--- Final Summary (Mean ± Std) ---\n",
      "R² Score: 0.9053 ± 0.0009\n",
      "MSE     : 0.3178 ± 0.0284\n",
      "\n",
      "Top 10 Learned Edges for Seed 11:\n",
      "Edge (148, 168) -> Weight: 0.3658\n",
      "Edge (168, 692) -> Weight: 0.2741\n",
      "Edge (375, 909) -> Weight: 0.2681\n",
      "Edge (233, 741) -> Weight: 0.2521\n",
      "Edge (459, 528) -> Weight: 0.2518\n",
      "Edge (538, 546) -> Weight: 0.2451\n",
      "Edge (419, 736) -> Weight: 0.2325\n",
      "Edge (141, 546) -> Weight: 0.2302\n",
      "Edge (141, 538) -> Weight: 0.2283\n",
      "Edge (283, 325) -> Weight: 0.2264\n",
      "\n",
      "Top 10 Learned Edges for Seed 18:\n",
      "Edge (148, 168) -> Weight: 0.3658\n",
      "Edge (168, 692) -> Weight: 0.2741\n",
      "Edge (375, 909) -> Weight: 0.2681\n",
      "Edge (233, 741) -> Weight: 0.2521\n",
      "Edge (459, 528) -> Weight: 0.2518\n",
      "Edge (538, 546) -> Weight: 0.2451\n",
      "Edge (419, 736) -> Weight: 0.2325\n",
      "Edge (141, 546) -> Weight: 0.2302\n",
      "Edge (141, 538) -> Weight: 0.2283\n",
      "Edge (283, 325) -> Weight: 0.2264\n",
      "\n",
      "Top 10 Learned Edges for Seed 36:\n",
      "Edge (148, 168) -> Weight: 0.3658\n",
      "Edge (168, 692) -> Weight: 0.2741\n",
      "Edge (375, 909) -> Weight: 0.2681\n",
      "Edge (233, 741) -> Weight: 0.2521\n",
      "Edge (459, 528) -> Weight: 0.2518\n",
      "Edge (538, 546) -> Weight: 0.2451\n",
      "Edge (419, 736) -> Weight: 0.2325\n",
      "Edge (141, 546) -> Weight: 0.2302\n",
      "Edge (141, 538) -> Weight: 0.2283\n",
      "Edge (283, 325) -> Weight: 0.2264\n",
      "\n",
      "Top 10 Learned Edges for Seed 40:\n",
      "Edge (148, 168) -> Weight: 0.3658\n",
      "Edge (168, 692) -> Weight: 0.2741\n",
      "Edge (375, 909) -> Weight: 0.2681\n",
      "Edge (233, 741) -> Weight: 0.2521\n",
      "Edge (459, 528) -> Weight: 0.2518\n",
      "Edge (538, 546) -> Weight: 0.2451\n",
      "Edge (419, 736) -> Weight: 0.2325\n",
      "Edge (141, 546) -> Weight: 0.2302\n",
      "Edge (141, 538) -> Weight: 0.2283\n",
      "Edge (283, 325) -> Weight: 0.2264\n",
      "\n",
      "Top 10 Learned Edges for Seed 67:\n",
      "Edge (148, 168) -> Weight: 0.3658\n",
      "Edge (168, 692) -> Weight: 0.2741\n",
      "Edge (375, 909) -> Weight: 0.2681\n",
      "Edge (233, 741) -> Weight: 0.2521\n",
      "Edge (459, 528) -> Weight: 0.2518\n",
      "Edge (538, 546) -> Weight: 0.2451\n",
      "Edge (419, 736) -> Weight: 0.2325\n",
      "Edge (141, 546) -> Weight: 0.2302\n",
      "Edge (141, 538) -> Weight: 0.2283\n",
      "Edge (283, 325) -> Weight: 0.2264\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEEDS = [11,18,36,40,67]\n",
    "GRAPH_SEED = 11\n",
    "\n",
    "GRAPH_LEARN_MEAN = 0.5\n",
    "GRAPH_LEARN_STD = 0.01\n",
    "GRAPH_LEARN_EPOCHS = 5000\n",
    "GRAPH_LEARN_ETA = 0.001\n",
    "\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "\n",
    "# ------------------------------------\n",
    "# Learn Graph Structure (Only minimize squared distances)\n",
    "# ------------------------------------\n",
    "def learn_graph(X: torch.Tensor, seed_graph: int):\n",
    "    X_np = X.cpu().numpy()\n",
    "    N = X_np.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(seed_graph)\n",
    "    W = rng.normal(GRAPH_LEARN_MEAN, GRAPH_LEARN_STD, size=(N, N))\n",
    "\n",
    "    i_idx, j_idx = np.triu_indices(N, k=1)\n",
    "    w = W[i_idx, j_idx].copy()\n",
    "    delL = np.sum((X_np[i_idx] - X_np[j_idx]) ** 2, axis=1)\n",
    "\n",
    "    best_w = w.copy()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for _ in range(GRAPH_LEARN_EPOCHS):\n",
    "        grad = 2.0 * delL  # 🔁 No regularization\n",
    "        w -= GRAPH_LEARN_ETA * grad\n",
    "        np.clip(w, 0.0, None, out=w)\n",
    "\n",
    "        loss = (delL * w).sum()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_w = w.copy()\n",
    "\n",
    "    valid_mask = best_w > 0\n",
    "    adj = np.zeros((N, N), dtype=int)\n",
    "    adj[i_idx[valid_mask], j_idx[valid_mask]] = 1\n",
    "    adj[j_idx[valid_mask], i_idx[valid_mask]] = 1\n",
    "\n",
    "    return adj, best_w, i_idx, j_idx\n",
    "\n",
    "# ------------------------------------\n",
    "# GNN Model\n",
    "# ------------------------------------\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# ------------------------------------\n",
    "# Train and Evaluate for One Seed\n",
    "# ------------------------------------\n",
    "def run_single_seed(X_raw, Y_raw, seed_model, seed_graph):\n",
    "    np.random.seed(seed_model)\n",
    "    torch.manual_seed(seed_model)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed_model)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_np = scaler.fit_transform(np.abs(X_raw.cpu().numpy()))\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "\n",
    "    adj, weights, i_idx, j_idx = learn_graph(X, seed_graph)\n",
    "    edge_index = torch.tensor(np.vstack(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed_model)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed_model)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(X.shape[0], dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index.to(DEVICE)\n",
    "    )\n",
    "    masks = {k: get_mask(v).to(DEVICE) for k, v in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx])}\n",
    "\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_true = data.y\n",
    "\n",
    "    r2 = r2_score(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "    mse = mean_squared_error(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "\n",
    "    return r2, mse, weights, i_idx, j_idx\n",
    "\n",
    "# ------------------------------------\n",
    "# Main Execution\n",
    "# ------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"1000_cylindrical_anomalies.csv\")\n",
    "    X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "    Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "\n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "    all_weights = []\n",
    "    all_edges = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        r2, mse, weights, i_idx, j_idx = run_single_seed(X_raw, Y_raw, seed_model=seed, seed_graph=GRAPH_SEED)\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "        all_weights.append(weights)\n",
    "        all_edges.append((i_idx, j_idx))\n",
    "        print(f\"Seed {seed} -> R²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    mse_scores = np.array(mse_scores)\n",
    "\n",
    "    print(\"\\n--- Final Summary (Mean ± Std) ---\")\n",
    "    print(f\"R² Score: {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "    print(f\"MSE     : {mse_scores.mean():.4f} ± {mse_scores.std():.4f}\")\n",
    "\n",
    "    # Print top 10 edges per seed\n",
    "    for seed, weights, (i_idx, j_idx) in zip(SEEDS, all_weights, all_edges):\n",
    "        edge_list = list(zip(i_idx, j_idx))\n",
    "        top_indices = np.argsort(weights)[-10:]\n",
    "        print(f\"\\nTop 10 Learned Edges for Seed {seed}:\")\n",
    "        for idx in reversed(top_indices):\n",
    "            print(f\"Edge {edge_list[idx]} -> Weight: {weights[idx]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
