{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e38dda",
   "metadata": {},
   "source": [
    "# ------------------------------------\n",
    "# No Alpha\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c616e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 16 -> R²: 0.9008, MSE: 0.4006\n",
      "Seed 56 -> R²: 0.9049, MSE: 0.4147\n",
      "Seed 61 -> R²: 0.9035, MSE: 0.3888\n",
      "Seed 78 -> R²: 0.9057, MSE: 0.3559\n",
      "Seed 81 -> R²: 0.9049, MSE: 0.4046\n",
      "\n",
      "--- Final Summary (Mean ± Std) ---\n",
      "R² Score: 0.9040 ± 0.0017\n",
      "MSE     : 0.3929 ± 0.0203\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "GRAPH_SEED = 11\n",
    "\n",
    "GRAPH_LEARN_MEAN = 0.5\n",
    "GRAPH_LEARN_STD = 0.01\n",
    "GRAPH_LEARN_EPOCHS = 5000\n",
    "GRAPH_LEARN_BETA = 0.001\n",
    "GRAPH_LEARN_ETA = 0.001\n",
    "\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "\n",
    "# ------------------------------------\n",
    "# Learn Graph Structure (L2 regularizer only)\n",
    "# ------------------------------------\n",
    "def learn_graph(X: torch.Tensor, seed_graph: int) -> np.ndarray:\n",
    "    X_np = X.cpu().numpy()\n",
    "    N = X_np.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(seed_graph)\n",
    "    W = rng.normal(GRAPH_LEARN_MEAN, GRAPH_LEARN_STD, size=(N, N))\n",
    "\n",
    "    i_idx, j_idx = np.triu_indices(N, k=1)\n",
    "    w = W[i_idx, j_idx].copy()\n",
    "    delL = np.sum((X_np[i_idx] - X_np[j_idx]) ** 2, axis=1)\n",
    "\n",
    "    best_w = w.copy()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for _ in range(GRAPH_LEARN_EPOCHS):\n",
    "        grad = 2.0 * delL + GRAPH_LEARN_BETA * w\n",
    "        w -= GRAPH_LEARN_ETA * grad\n",
    "        np.clip(w, 0.0, None, out=w)\n",
    "\n",
    "        loss = (delL * w).sum() + (GRAPH_LEARN_BETA / 2.0) * (w ** 2).sum()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_w = w.copy()\n",
    "\n",
    "    adj = np.zeros((N, N), dtype=int)\n",
    "    adj[i_idx[best_w > 0], j_idx[best_w > 0]] = 1\n",
    "    adj[j_idx[best_w > 0], i_idx[best_w > 0]] = 1\n",
    "\n",
    "    return adj\n",
    "\n",
    "# ------------------------------------\n",
    "# GNN Model\n",
    "# ------------------------------------\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# ------------------------------------\n",
    "# Train and Evaluate for One Seed\n",
    "# ------------------------------------\n",
    "def run_single_seed(X_raw, Y_raw, seed_model, seed_graph):\n",
    "    np.random.seed(seed_model)\n",
    "    torch.manual_seed(seed_model)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed_model)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_np = scaler.fit_transform(np.abs(X_raw.cpu().numpy()))\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "\n",
    "    adj = learn_graph(X, seed_graph)\n",
    "    edge_index = torch.tensor(np.vstack(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed_model)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed_model)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(X.shape[0], dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index.to(DEVICE)\n",
    "    )\n",
    "    masks = {k: get_mask(v).to(DEVICE) for k, v in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx])}\n",
    "\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_true = data.y\n",
    "\n",
    "    r2 = r2_score(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "    mse = mean_squared_error(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "\n",
    "    return r2, mse\n",
    "\n",
    "# ------------------------------------\n",
    "# Main Execution\n",
    "# ------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"1000_spherical_anomalies.csv\")\n",
    "    X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "    Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "\n",
    "    SEEDS = [16,56,61,78,81]  # 5 random seeds\n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        r2, mse = run_single_seed(X_raw, Y_raw, seed_model=seed, seed_graph=GRAPH_SEED)\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "        print(f\"Seed {seed} -> R²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    mse_scores = np.array(mse_scores)\n",
    "\n",
    "    print(\"\\n--- Final Summary (Mean ± Std) ---\")\n",
    "    print(f\"R² Score: {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "    print(f\"MSE     : {mse_scores.mean():.4f} ± {mse_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb8239",
   "metadata": {},
   "source": [
    "# ------------------------------------\n",
    "# No Beta\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da8acbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 17 -> R²: 0.9373, MSE: 0.2418\n",
      "Seed 23 -> R²: 0.9123, MSE: 0.3561\n",
      "Seed 37 -> R²: 0.9530, MSE: 0.1571\n",
      "Seed 49 -> R²: 0.9266, MSE: 0.2520\n",
      "Seed 60 -> R²: 0.9151, MSE: 0.3125\n",
      "\n",
      "--- Final Summary (Mean ± Std) ---\n",
      "R² Score: 0.9289 ± 0.0150\n",
      "MSE     : 0.2639 ± 0.0677\n",
      "\n",
      "Top 10 Learned Edges for Seed 17:\n",
      "Edge (135, 329) -> Weight: 2.8082\n",
      "Edge (601, 699) -> Weight: 2.5339\n",
      "Edge (407, 478) -> Weight: 2.4414\n",
      "Edge (911, 988) -> Weight: 2.4018\n",
      "Edge (185, 195) -> Weight: 2.3386\n",
      "Edge (129, 664) -> Weight: 2.3372\n",
      "Edge (541, 725) -> Weight: 2.3270\n",
      "Edge (127, 759) -> Weight: 2.3145\n",
      "Edge (260, 457) -> Weight: 2.3127\n",
      "Edge (76, 78) -> Weight: 2.2654\n",
      "\n",
      "Top 10 Learned Edges for Seed 23:\n",
      "Edge (135, 329) -> Weight: 2.8082\n",
      "Edge (601, 699) -> Weight: 2.5339\n",
      "Edge (407, 478) -> Weight: 2.4414\n",
      "Edge (911, 988) -> Weight: 2.4018\n",
      "Edge (185, 195) -> Weight: 2.3386\n",
      "Edge (129, 664) -> Weight: 2.3372\n",
      "Edge (541, 725) -> Weight: 2.3270\n",
      "Edge (127, 759) -> Weight: 2.3145\n",
      "Edge (260, 457) -> Weight: 2.3127\n",
      "Edge (76, 78) -> Weight: 2.2654\n",
      "\n",
      "Top 10 Learned Edges for Seed 37:\n",
      "Edge (135, 329) -> Weight: 2.8082\n",
      "Edge (601, 699) -> Weight: 2.5339\n",
      "Edge (407, 478) -> Weight: 2.4414\n",
      "Edge (911, 988) -> Weight: 2.4018\n",
      "Edge (185, 195) -> Weight: 2.3386\n",
      "Edge (129, 664) -> Weight: 2.3372\n",
      "Edge (541, 725) -> Weight: 2.3270\n",
      "Edge (127, 759) -> Weight: 2.3145\n",
      "Edge (260, 457) -> Weight: 2.3127\n",
      "Edge (76, 78) -> Weight: 2.2654\n",
      "\n",
      "Top 10 Learned Edges for Seed 49:\n",
      "Edge (135, 329) -> Weight: 2.8082\n",
      "Edge (601, 699) -> Weight: 2.5339\n",
      "Edge (407, 478) -> Weight: 2.4414\n",
      "Edge (911, 988) -> Weight: 2.4018\n",
      "Edge (185, 195) -> Weight: 2.3386\n",
      "Edge (129, 664) -> Weight: 2.3372\n",
      "Edge (541, 725) -> Weight: 2.3270\n",
      "Edge (127, 759) -> Weight: 2.3145\n",
      "Edge (260, 457) -> Weight: 2.3127\n",
      "Edge (76, 78) -> Weight: 2.2654\n",
      "\n",
      "Top 10 Learned Edges for Seed 60:\n",
      "Edge (135, 329) -> Weight: 2.8082\n",
      "Edge (601, 699) -> Weight: 2.5339\n",
      "Edge (407, 478) -> Weight: 2.4414\n",
      "Edge (911, 988) -> Weight: 2.4018\n",
      "Edge (185, 195) -> Weight: 2.3386\n",
      "Edge (129, 664) -> Weight: 2.3372\n",
      "Edge (541, 725) -> Weight: 2.3270\n",
      "Edge (127, 759) -> Weight: 2.3145\n",
      "Edge (260, 457) -> Weight: 2.3127\n",
      "Edge (76, 78) -> Weight: 2.2654\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# ------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEEDS = [17,23,37,49,60]\n",
    "GRAPH_SEED = 11\n",
    "\n",
    "GRAPH_LEARN_MEAN = 0.5\n",
    "GRAPH_LEARN_STD = 0.01\n",
    "GRAPH_LEARN_EPOCHS = 5000\n",
    "GRAPH_LEARN_ALPHA = 1.0\n",
    "GRAPH_LEARN_ETA = 0.001\n",
    "\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "\n",
    "# ------------------------------------\n",
    "# Learn Graph Structure (All edges with positive weight)\n",
    "# ------------------------------------\n",
    "def learn_graph(X: torch.Tensor, seed_graph: int):\n",
    "    X_np = X.cpu().numpy()\n",
    "    N = X_np.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(seed_graph)\n",
    "    W = rng.normal(GRAPH_LEARN_MEAN, GRAPH_LEARN_STD, size=(N, N))\n",
    "\n",
    "    i_idx, j_idx = np.triu_indices(N, k=1)\n",
    "    w = W[i_idx, j_idx].copy()\n",
    "    delL = np.sum((X_np[i_idx] - X_np[j_idx]) ** 2, axis=1)\n",
    "\n",
    "    row = np.concatenate([i_idx, j_idx])\n",
    "    col = np.concatenate([np.arange(len(i_idx)), np.arange(len(j_idx))])\n",
    "    S = coo_matrix((np.ones(len(row)), (row, col)), shape=(N, len(i_idx))).tocsc()\n",
    "    S_T = S.T\n",
    "\n",
    "    best_w = w.copy()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for _ in range(GRAPH_LEARN_EPOCHS):\n",
    "        Sw = S.dot(w)\n",
    "        inv_Sw = np.zeros_like(Sw)\n",
    "        nonzero = Sw > 0\n",
    "        inv_Sw[nonzero] = 1.0 / Sw[nonzero]\n",
    "        grad = 2.0 * delL - GRAPH_LEARN_ALPHA * S_T.dot(inv_Sw)\n",
    "        w -= GRAPH_LEARN_ETA * grad\n",
    "        np.clip(w, 0.0, None, out=w)\n",
    "\n",
    "        loss = (delL * w).sum() - GRAPH_LEARN_ALPHA * np.sum(np.log(Sw[nonzero]))\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_w = w.copy()\n",
    "\n",
    "    # Use all edges with positive weight\n",
    "    valid_mask = best_w > 0\n",
    "    adj = np.zeros((N, N), dtype=int)\n",
    "    adj[i_idx[valid_mask], j_idx[valid_mask]] = 1\n",
    "    adj[j_idx[valid_mask], i_idx[valid_mask]] = 1\n",
    "\n",
    "    return adj, best_w, i_idx, j_idx\n",
    "\n",
    "# ------------------------------------\n",
    "# GNN Model\n",
    "# ------------------------------------\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# ------------------------------------\n",
    "# Train and Evaluate for One Seed\n",
    "# ------------------------------------\n",
    "def run_single_seed(X_raw, Y_raw, seed_model, seed_graph):\n",
    "    np.random.seed(seed_model)\n",
    "    torch.manual_seed(seed_model)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed_model)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_np = scaler.fit_transform(np.abs(X_raw.cpu().numpy()))\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "\n",
    "    adj, weights, i_idx, j_idx = learn_graph(X, seed_graph)\n",
    "    edge_index = torch.tensor(np.vstack(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed_model)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed_model)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(X.shape[0], dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index.to(DEVICE)\n",
    "    )\n",
    "    masks = {k: get_mask(v).to(DEVICE) for k, v in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx])}\n",
    "\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=50)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_true = data.y\n",
    "\n",
    "    r2 = r2_score(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "    mse = mean_squared_error(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "\n",
    "    return r2, mse, weights, i_idx, j_idx\n",
    "\n",
    "# ------------------------------------\n",
    "# Main Execution\n",
    "# ------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"1000_spherical_anomalies.csv\")\n",
    "    X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "    Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "\n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "    all_weights = []\n",
    "    all_edges = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        r2, mse, weights, i_idx, j_idx = run_single_seed(X_raw, Y_raw, seed_model=seed, seed_graph=GRAPH_SEED)\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "        all_weights.append(weights)\n",
    "        all_edges.append((i_idx, j_idx))\n",
    "        print(f\"Seed {seed} -> R²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    mse_scores = np.array(mse_scores)\n",
    "\n",
    "    print(\"\\n--- Final Summary (Mean ± Std) ---\")\n",
    "    print(f\"R² Score: {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "    print(f\"MSE     : {mse_scores.mean():.4f} ± {mse_scores.std():.4f}\")\n",
    "\n",
    "    # Print top 10 weighted edges for each seed\n",
    "    for seed, weights, (i_idx, j_idx) in zip(SEEDS, all_weights, all_edges):\n",
    "        edge_list = list(zip(i_idx, j_idx))\n",
    "        top_indices = np.argsort(weights)[-10:]\n",
    "        print(f\"\\nTop 10 Learned Edges for Seed {seed}:\")\n",
    "        for idx in reversed(top_indices):\n",
    "            print(f\"Edge {edge_list[idx]} -> Weight: {weights[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5afef",
   "metadata": {},
   "source": [
    "# ------------------------------------\n",
    "# NO Alpha and No Beta\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86c2d516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 10 -> R²: 0.8864, MSE: 0.3439\n",
      "Seed 25 -> R²: 0.8927, MSE: 0.3868\n",
      "Seed 40 -> R²: 0.8889, MSE: 0.4007\n",
      "Seed 59 -> R²: 0.8892, MSE: 0.3697\n",
      "Seed 76 -> R²: 0.8880, MSE: 0.3953\n",
      "\n",
      "--- Final Summary (Mean ± Std) ---\n",
      "R² Score: 0.8890 ± 0.0021\n",
      "MSE     : 0.3793 ± 0.0206\n",
      "\n",
      "Top 10 Learned Edges for Seed 10:\n",
      "Edge (289, 309) -> Weight: 0.4898\n",
      "Edge (0, 332) -> Weight: 0.4743\n",
      "Edge (24, 421) -> Weight: 0.4739\n",
      "Edge (748, 790) -> Weight: 0.4713\n",
      "Edge (519, 920) -> Weight: 0.4680\n",
      "Edge (9, 289) -> Weight: 0.4638\n",
      "Edge (0, 597) -> Weight: 0.4633\n",
      "Edge (9, 887) -> Weight: 0.4550\n",
      "Edge (438, 576) -> Weight: 0.4550\n",
      "Edge (530, 691) -> Weight: 0.4548\n",
      "\n",
      "Top 10 Learned Edges for Seed 25:\n",
      "Edge (289, 309) -> Weight: 0.4898\n",
      "Edge (0, 332) -> Weight: 0.4743\n",
      "Edge (24, 421) -> Weight: 0.4739\n",
      "Edge (748, 790) -> Weight: 0.4713\n",
      "Edge (519, 920) -> Weight: 0.4680\n",
      "Edge (9, 289) -> Weight: 0.4638\n",
      "Edge (0, 597) -> Weight: 0.4633\n",
      "Edge (9, 887) -> Weight: 0.4550\n",
      "Edge (438, 576) -> Weight: 0.4550\n",
      "Edge (530, 691) -> Weight: 0.4548\n",
      "\n",
      "Top 10 Learned Edges for Seed 40:\n",
      "Edge (289, 309) -> Weight: 0.4898\n",
      "Edge (0, 332) -> Weight: 0.4743\n",
      "Edge (24, 421) -> Weight: 0.4739\n",
      "Edge (748, 790) -> Weight: 0.4713\n",
      "Edge (519, 920) -> Weight: 0.4680\n",
      "Edge (9, 289) -> Weight: 0.4638\n",
      "Edge (0, 597) -> Weight: 0.4633\n",
      "Edge (9, 887) -> Weight: 0.4550\n",
      "Edge (438, 576) -> Weight: 0.4550\n",
      "Edge (530, 691) -> Weight: 0.4548\n",
      "\n",
      "Top 10 Learned Edges for Seed 59:\n",
      "Edge (289, 309) -> Weight: 0.4898\n",
      "Edge (0, 332) -> Weight: 0.4743\n",
      "Edge (24, 421) -> Weight: 0.4739\n",
      "Edge (748, 790) -> Weight: 0.4713\n",
      "Edge (519, 920) -> Weight: 0.4680\n",
      "Edge (9, 289) -> Weight: 0.4638\n",
      "Edge (0, 597) -> Weight: 0.4633\n",
      "Edge (9, 887) -> Weight: 0.4550\n",
      "Edge (438, 576) -> Weight: 0.4550\n",
      "Edge (530, 691) -> Weight: 0.4548\n",
      "\n",
      "Top 10 Learned Edges for Seed 76:\n",
      "Edge (289, 309) -> Weight: 0.4898\n",
      "Edge (0, 332) -> Weight: 0.4743\n",
      "Edge (24, 421) -> Weight: 0.4739\n",
      "Edge (748, 790) -> Weight: 0.4713\n",
      "Edge (519, 920) -> Weight: 0.4680\n",
      "Edge (9, 289) -> Weight: 0.4638\n",
      "Edge (0, 597) -> Weight: 0.4633\n",
      "Edge (9, 887) -> Weight: 0.4550\n",
      "Edge (438, 576) -> Weight: 0.4550\n",
      "Edge (530, 691) -> Weight: 0.4548\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEEDS = [10,25,40,59,76]\n",
    "GRAPH_SEED = 11\n",
    "\n",
    "GRAPH_LEARN_MEAN = 0.5\n",
    "GRAPH_LEARN_STD = 0.01\n",
    "GRAPH_LEARN_EPOCHS = 5000\n",
    "GRAPH_LEARN_ETA = 0.001\n",
    "\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "\n",
    "# ------------------------------------\n",
    "# Learn Graph Structure (Only minimize squared distances)\n",
    "# ------------------------------------\n",
    "def learn_graph(X: torch.Tensor, seed_graph: int):\n",
    "    X_np = X.cpu().numpy()\n",
    "    N = X_np.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(seed_graph)\n",
    "    W = rng.normal(GRAPH_LEARN_MEAN, GRAPH_LEARN_STD, size=(N, N))\n",
    "\n",
    "    i_idx, j_idx = np.triu_indices(N, k=1)\n",
    "    w = W[i_idx, j_idx].copy()\n",
    "    delL = np.sum((X_np[i_idx] - X_np[j_idx]) ** 2, axis=1)\n",
    "\n",
    "    best_w = w.copy()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for _ in range(GRAPH_LEARN_EPOCHS):\n",
    "        grad = 2.0 * delL  # 🔁 No regularization\n",
    "        w -= GRAPH_LEARN_ETA * grad\n",
    "        np.clip(w, 0.0, None, out=w)\n",
    "\n",
    "        loss = (delL * w).sum()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_w = w.copy()\n",
    "\n",
    "    valid_mask = best_w > 0\n",
    "    adj = np.zeros((N, N), dtype=int)\n",
    "    adj[i_idx[valid_mask], j_idx[valid_mask]] = 1\n",
    "    adj[j_idx[valid_mask], i_idx[valid_mask]] = 1\n",
    "\n",
    "    return adj, best_w, i_idx, j_idx\n",
    "\n",
    "# ------------------------------------\n",
    "# GNN Model\n",
    "# ------------------------------------\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# ------------------------------------\n",
    "# Train and Evaluate for One Seed\n",
    "# ------------------------------------\n",
    "def run_single_seed(X_raw, Y_raw, seed_model, seed_graph):\n",
    "    np.random.seed(seed_model)\n",
    "    torch.manual_seed(seed_model)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed_model)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_np = scaler.fit_transform(np.abs(X_raw.cpu().numpy()))\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "\n",
    "    adj, weights, i_idx, j_idx = learn_graph(X, seed_graph)\n",
    "    edge_index = torch.tensor(np.vstack(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed_model)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed_model)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(X.shape[0], dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index.to(DEVICE)\n",
    "    )\n",
    "    masks = {k: get_mask(v).to(DEVICE) for k, v in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx])}\n",
    "\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_true = data.y\n",
    "\n",
    "    r2 = r2_score(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "    mse = mean_squared_error(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "\n",
    "    return r2, mse, weights, i_idx, j_idx\n",
    "\n",
    "# ------------------------------------\n",
    "# Main Execution\n",
    "# ------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"1000_spherical_anomalies.csv\")\n",
    "    X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "    Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "\n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "    all_weights = []\n",
    "    all_edges = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        r2, mse, weights, i_idx, j_idx = run_single_seed(X_raw, Y_raw, seed_model=seed, seed_graph=GRAPH_SEED)\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "        all_weights.append(weights)\n",
    "        all_edges.append((i_idx, j_idx))\n",
    "        print(f\"Seed {seed} -> R²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    mse_scores = np.array(mse_scores)\n",
    "\n",
    "    print(\"\\n--- Final Summary (Mean ± Std) ---\")\n",
    "    print(f\"R² Score: {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "    print(f\"MSE     : {mse_scores.mean():.4f} ± {mse_scores.std():.4f}\")\n",
    "\n",
    "    # Print top 10 edges per seed\n",
    "    for seed, weights, (i_idx, j_idx) in zip(SEEDS, all_weights, all_edges):\n",
    "        edge_list = list(zip(i_idx, j_idx))\n",
    "        top_indices = np.argsort(weights)[-10:]\n",
    "        print(f\"\\nTop 10 Learned Edges for Seed {seed}:\")\n",
    "        for idx in reversed(top_indices):\n",
    "            print(f\"Edge {edge_list[idx]} -> Weight: {weights[idx]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
