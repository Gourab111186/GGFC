{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e652a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 8 -> R²: 0.9603, MSE: 0.1896\n",
      "Seed 74 -> R²: 0.9576, MSE: 0.1791\n",
      "Seed 88 -> R²: 0.9701, MSE: 0.1332\n",
      "Seed 94 -> R²: 0.9537, MSE: 0.1486\n",
      "Seed 111 -> R²: 0.9680, MSE: 0.1356\n",
      "\n",
      "Average Evaluation Metrics Across Seeds:\n",
      "Mean R²: 0.9619, Std R²: 0.0062\n",
      "Mean MSE: 0.1572, Std MSE: 0.0230\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy import sparse\n",
    "\n",
    "# ------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEEDS = [8,74,88,94,111]\n",
    "KNN_K = 5\n",
    "HEAT_KERNEL_T = 1.0\n",
    "\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "\n",
    "# ------------------------------------\n",
    "# Build Weighted KNN Graph\n",
    "# ------------------------------------\n",
    "def build_knn_graph(X: torch.Tensor, k: int, t: float = 1.0) -> np.ndarray:\n",
    "    X_np = X.cpu().numpy()\n",
    "    W = kneighbors_graph(X_np, k, mode='distance', include_self=False)\n",
    "    W = W.maximum(W.T)  # make symmetric\n",
    "\n",
    "    # Apply heat kernel weights: exp(-d^2 / 4t)\n",
    "    W.data = np.exp(-W.data ** 2 / (4 * t))\n",
    "\n",
    "    # Convert to binary adjacency matrix for edge_index\n",
    "    adj = (W > 0).astype(int).toarray()\n",
    "\n",
    "    return adj\n",
    "\n",
    "# ------------------------------------\n",
    "# GNN Model\n",
    "# ------------------------------------\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# ------------------------------------\n",
    "# Train and Evaluate for One Seed\n",
    "# ------------------------------------\n",
    "def run_single_seed(X_raw, Y_raw, seed_model):\n",
    "    np.random.seed(seed_model)\n",
    "    torch.manual_seed(seed_model)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed_model)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_np = scaler.fit_transform(np.abs(X_raw.cpu().numpy()))\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "\n",
    "    adj = build_knn_graph(X, KNN_K, t=HEAT_KERNEL_T)\n",
    "    edge_index = torch.tensor(np.vstack(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed_model)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed_model)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(X.shape[0], dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index.to(DEVICE)\n",
    "    )\n",
    "    masks = {k: get_mask(v).to(DEVICE) for k, v in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx])}\n",
    "\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=200)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_true = data.y\n",
    "\n",
    "    r2 = r2_score(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "    mse = mean_squared_error(y_true[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "\n",
    "    return r2, mse\n",
    "\n",
    "# ------------------------------------\n",
    "# Main Execution\n",
    "# ------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"1000_cylindrical_anomalies.csv\")\n",
    "    X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "    Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "\n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        r2, mse = run_single_seed(X_raw, Y_raw, seed_model=seed)\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "        print(f\"Seed {seed} -> R²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    print(\"\\nAverage Evaluation Metrics Across Seeds:\")\n",
    "    print(f\"Mean R²: {np.mean(r2_scores):.4f}, Std R²: {np.std(r2_scores):.4f}\")\n",
    "    print(f\"Mean MSE: {np.mean(mse_scores):.4f}, Std MSE: {np.std(mse_scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
