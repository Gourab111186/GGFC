{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a830a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed: 8\n",
      "R²: 0.8443, MSE: 0.5020\n",
      "Running experiment with seed: 35\n",
      "R²: 0.8656, MSE: 0.4345\n",
      "Running experiment with seed: 43\n",
      "R²: 0.8617, MSE: 0.5628\n",
      "Running experiment with seed: 58\n",
      "R²: 0.8618, MSE: 0.4868\n",
      "Running experiment with seed: 70\n",
      "R²: 0.8512, MSE: 0.5108\n",
      "\n",
      "Results across seeds:\n",
      "Mean R²: 0.8569, Std R²: 0.0079\n",
      "Mean MSE: 0.4994, Std MSE: 0.0413\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Seeds for reproducibility\n",
    "SEEDS = [8, 35, 43, 58, 70]\n",
    "\n",
    "# GraphSAGE & training hyperparameters\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "\n",
    "# ------------------------------------\n",
    "# GNN Model Definition\n",
    "# ------------------------------------\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# ------------------------------------\n",
    "# Train and Evaluate for One Seed\n",
    "# ------------------------------------\n",
    "def run_single_seed(X_raw, Y_raw, seed_model):\n",
    "    # Set random seeds\n",
    "    np.random.seed(seed_model)\n",
    "    torch.manual_seed(seed_model)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed_model)\n",
    "\n",
    "    # Preprocess features\n",
    "    scaler = StandardScaler()\n",
    "    X_np = scaler.fit_transform(np.abs(X_raw.cpu().numpy()))\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "\n",
    "    # Create identity graph: only self-loops\n",
    "    N = X.size(0)\n",
    "    node_ids = torch.arange(N, device=DEVICE)\n",
    "    edge_index = torch.stack([node_ids, node_ids], dim=0)  # shape [2, N]\n",
    "\n",
    "    # Split indices\n",
    "    idx = np.arange(N)\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed_model)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed_model)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(N, dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask.to(DEVICE)\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index\n",
    "    )\n",
    "    masks = {\n",
    "        'train': get_mask(train_idx),\n",
    "        'val': get_mask(val_idx),\n",
    "        'test': get_mask(test_idx)\n",
    "    }\n",
    "\n",
    "    # Initialize model, optimizer, scheduler, and loss\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(data.x, data.edge_index)\n",
    "\n",
    "    # Compute metrics\n",
    "    y_true = data.y\n",
    "    r2 = r2_score(y_true[masks['test']].cpu().numpy(), predictions[masks['test']].cpu().numpy())\n",
    "    mse = mean_squared_error(y_true[masks['test']].cpu().numpy(), predictions[masks['test']].cpu().numpy())\n",
    "\n",
    "    return r2, mse\n",
    "\n",
    "# ------------------------------------\n",
    "# Run Experiment for Multiple Seeds\n",
    "# ------------------------------------\n",
    "def run_experiment_for_multiple_seeds(X_raw, Y_raw):\n",
    "    r2_scores, mse_scores = [], []\n",
    "    for seed in SEEDS:\n",
    "        print(f\"Running experiment with seed: {seed}\")\n",
    "        r2, mse = run_single_seed(X_raw, Y_raw, seed_model=seed)\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "        print(f\"R²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    print(\"\\nResults across seeds:\")\n",
    "    print(f\"Mean R²: {np.mean(r2_scores):.4f}, Std R²: {np.std(r2_scores):.4f}\")\n",
    "    print(f\"Mean MSE: {np.mean(mse_scores):.4f}, Std MSE: {np.std(mse_scores):.4f}\")\n",
    "\n",
    "# ------------------------------------\n",
    "# Main Execution\n",
    "# ------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"1000_spherical_anomalies.csv\")\n",
    "    X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "    Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "\n",
    "    run_experiment_for_multiple_seeds(X_raw, Y_raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
