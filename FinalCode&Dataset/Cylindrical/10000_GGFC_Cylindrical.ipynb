{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d9d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph structure learned and saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "GRAPH_SEED = 11\n",
    "GRAPH_LEARN_MEAN = 0.5\n",
    "GRAPH_LEARN_STD = 0.01\n",
    "GRAPH_LEARN_EPOCHS = 5000\n",
    "GRAPH_LEARN_ALPHA = 1.0\n",
    "GRAPH_LEARN_BETA = 2.0\n",
    "GRAPH_LEARN_ETA = 0.001\n",
    "\n",
    "def learn_graph(X: torch.Tensor, seed_graph: int) -> np.ndarray:\n",
    "    X_np = X.cpu().numpy()\n",
    "    N = X_np.shape[0]\n",
    "    rng = np.random.default_rng(seed_graph)\n",
    "    W = rng.normal(GRAPH_LEARN_MEAN, GRAPH_LEARN_STD, size=(N, N))\n",
    "\n",
    "    i_idx, j_idx = np.triu_indices(N, k=1)\n",
    "    w = W[i_idx, j_idx].copy()\n",
    "    delL = np.sum((X_np[i_idx] - X_np[j_idx]) ** 2, axis=1)\n",
    "\n",
    "    row = np.concatenate([i_idx, j_idx])\n",
    "    col = np.concatenate([np.arange(len(i_idx)), np.arange(len(j_idx))])\n",
    "    S = coo_matrix((np.ones(len(row)), (row, col)), shape=(N, len(i_idx))).tocsc()\n",
    "    S_T = S.T\n",
    "\n",
    "    best_w = w.copy()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for _ in range(GRAPH_LEARN_EPOCHS):\n",
    "        Sw = S.dot(w)\n",
    "        inv_Sw = np.zeros_like(Sw)\n",
    "        nonzero = Sw > 0\n",
    "        inv_Sw[nonzero] = 1.0 / Sw[nonzero]\n",
    "        grad = 2.0 * delL + GRAPH_LEARN_BETA * w - GRAPH_LEARN_ALPHA * S_T.dot(inv_Sw)\n",
    "        w -= GRAPH_LEARN_ETA * grad\n",
    "        np.clip(w, 0.0, None, out=w)\n",
    "\n",
    "        loss = (delL * w).sum() + (GRAPH_LEARN_BETA / 2.0) * (w ** 2).sum() - GRAPH_LEARN_ALPHA * np.sum(np.log(Sw[nonzero]))\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_w = w.copy()\n",
    "\n",
    "    k = max(1, int(0.05 * len(best_w)))\n",
    "    threshold = np.partition(best_w, -k)[-k]\n",
    "    top_mask = best_w >= threshold\n",
    "\n",
    "    adj = np.zeros((N, N), dtype=int)\n",
    "    adj[i_idx[top_mask], j_idx[top_mask]] = 1\n",
    "    adj[j_idx[top_mask], i_idx[top_mask]] = 1\n",
    "\n",
    "    return adj\n",
    "\n",
    "# ----- Graph Construction -----\n",
    "df = pd.read_csv(\"10000_cylindrical_anomalies.csv\")\n",
    "X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = torch.tensor(scaler.fit_transform(np.abs(X_raw.numpy())), dtype=torch.float32)\n",
    "\n",
    "adj_matrix = learn_graph(X_scaled, seed_graph=GRAPH_SEED)\n",
    "np.save(\"learned_adj_graph10k.npy\", adj_matrix)\n",
    "print(\"Graph structure learned and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Hyperparameters\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAGE_HIDDEN_DIM = 128\n",
    "SAGE_DROPOUT = 0.2\n",
    "LR = 4e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15000\n",
    "PATIENCE = 1000\n",
    "SEEDS = [8]\n",
    "\n",
    "class GraphSAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.out = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, p=SAGE_DROPOUT, training=self.training)\n",
    "        return self.out(x, edge_index)\n",
    "\n",
    "# Load Data and Graph\n",
    "df = pd.read_csv(\"10000_cylindrical_anomalies.csv\")\n",
    "X_raw = torch.tensor(df.iloc[:, :22].values, dtype=torch.float32)\n",
    "Y_raw = torch.tensor(df.iloc[:, 22:23].values, dtype=torch.float32)\n",
    "scaler = StandardScaler()\n",
    "X = torch.tensor(scaler.fit_transform(np.abs(X_raw.numpy())), dtype=torch.float32)\n",
    "adj = np.load(\"learned_adj_graph10k.npy\")\n",
    "edge_index = torch.tensor(np.vstack(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "results_r2 = []\n",
    "results_mse = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    train_idx, temp_idx = train_test_split(idx, test_size=0.2, random_state=seed)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed)\n",
    "\n",
    "    def get_mask(idxs):\n",
    "        mask = torch.zeros(X.shape[0], dtype=torch.bool)\n",
    "        mask[idxs] = True\n",
    "        return mask\n",
    "\n",
    "    data = Data(\n",
    "        x=X.to(DEVICE),\n",
    "        y=Y_raw.to(DEVICE),\n",
    "        edge_index=edge_index.to(DEVICE)\n",
    "    )\n",
    "    masks = {k: get_mask(v).to(DEVICE) for k, v in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx])}\n",
    "\n",
    "    model = GraphSAGENet(X.size(1), SAGE_HIDDEN_DIM, Y_raw.size(1)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=200)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[masks['train']], data.y[masks['train']])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(data.x, data.edge_index)[masks['val']], data.y[masks['val']])\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        r2 = r2_score(data.y[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "        mse = mean_squared_error(data.y[masks['test']].cpu().numpy(), out[masks['test']].cpu().numpy())\n",
    "        print(f\"Seed {seed:3d} | R²: {r2:.4f} | MSE: {mse:.4f}\")\n",
    "        results_r2.append(r2)\n",
    "        results_mse.append(mse)\n",
    "\n",
    "print(\"\\n--- R² Summary ---\")\n",
    "print(f\"Mean R² = {np.mean(results_r2):.4f}, Std = {np.std(results_r2):.4f}\")\n",
    "print(\"\\n--- MSE Summary ---\")\n",
    "print(f\"Mean MSE = {np.mean(results_mse):.4f}, Std = {np.std(results_mse):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
